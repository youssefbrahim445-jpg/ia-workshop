{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa92f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (0.31.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39fb912d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: groq in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (0.31.0)\n",
      "Requirement already satisfied: dotenv in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (0.9.9)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (2.11.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from dotenv) (1.1.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\pc-lenovo\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install groq dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "117a549c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models have revolutionized the way we interact with technology and access information. These models use complex algorithms and large amounts of data to generate human-like text, translations, and conversations at incredible speeds.\n",
      "\n",
      "The importance of fast language models can be seen in several areas:\n",
      "\n",
      "1. **Efficient Communication**: Fast language models enable rapid communication across languages and cultures, breaking down barriers and expanding global understanding. They facilitate instant translation, allowing people to connect with others who speak different languages.\n",
      "2. **Information Retrieval**: Fast language models can quickly process and analyze vast amounts of data, providing relevant information and insights in a matter of seconds. This enables users to access knowledge and answers quickly, making them more efficient in their work and personal lives.\n",
      "3. **Content Generation**: Fast language models can generate high-quality content, such as articles, social media posts, and even entire books, at unprecedented speeds. This has far-reaching implications for content creators, marketers, and publishers.\n",
      "4. **Virtual Assistants**: Fast language models power virtual assistants like chatbots, voice assistants, and customer service platforms. These assistants provide 24/7 support, answering queries, and helping users with tasks and transactions.\n",
      "5. **Research and Development**: Fast language models accelerate research in fields like natural language processing, machine learning, and artificial intelligence. They enable scientists and engineers to test hypotheses, simulate experiments, and explore new ideas at an unprecedented pace.\n",
      "6. **Accessibility**: Fast language models can help people with disabilities, such as those with speech or hearing impairments, by providing real-time transcription, translation, and communication tools.\n",
      "7. **Business Automation**: Fast language models can automate tasks like data entry, document processing, and customer service, freeing up human resources for more strategic and creative work.\n",
      "8. **Education and Learning**: Fast language models can facilitate personalized learning, adaptive assessments, and intelligent tutoring systems, making education more effective and accessible.\n",
      "\n",
      "In summary, fast language models have transformed the way we interact, access information, and generate content. Their impact is felt across industries, cultures, and aspects of society, enabling faster, more efficient, and more effective communication, information retrieval, and content creation.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from groq import Groq\n",
    "\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\": \"system\",\n",
    "            \"content\":\"you are an incpert in geography dont ask any question about geography \"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c7ad030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models are crucial in today's digital landscape, and their importance can be seen in several areas:\n",
      "\n",
      "1. **Efficient Processing**: Fast language models enable quick processing of large volumes of text data, which is essential for applications like language translation, sentiment analysis, and text classification. This efficiency allows for real-time processing, making it possible to analyze and respond to user input promptly.\n",
      "2. **Improved User Experience**: Fast language models enhance the user experience by providing instant results, allowing users to interact with chatbots, virtual assistants, and other language-based interfaces more naturally and efficiently. Quick responses also reduce latency, making the interaction feel more seamless.\n",
      "3. **Scalability**: Fast language models are essential for large-scale applications, such as social media monitoring, customer service platforms, and language translation services. They enable these platforms to handle a vast number of requests simultaneously, without compromising performance.\n",
      "4. **Real-Time Insights**: Fast language models facilitate real-time insights and analysis, which is vital for applications like:\n",
      "\t* Sentiment analysis: monitoring public opinion and sentiment on social media, news, or reviews.\n",
      "\t* News aggregation: providing up-to-the-minute news summaries and alerts.\n",
      "\t* Social media monitoring: tracking brand mentions, hashtags, and trending topics.\n",
      "5. **Competitive Advantage**: Organizations that leverage fast language models can gain a competitive advantage by:\n",
      "\t* Responding quickly to customer inquiries and concerns.\n",
      "\t* Providing timely and relevant information to users.\n",
      "\t* Analyzing large datasets to identify trends, patterns, and opportunities.\n",
      "6. **Cost Savings**: Fast language models can help reduce costs by:\n",
      "\t* Automating tasks: reducing the need for human intervention and manual processing.\n",
      "\t* Minimizing infrastructure: requiring less computational resources and infrastructure to process large volumes of text data.\n",
      "7. **Enhanced Security**: Fast language models can be used to detect and respond to security threats in real-time, such as:\n",
      "\t* Identifying phishing attempts and malware.\n",
      "\t* Detecting and preventing cyber attacks.\n",
      "8. **Accessibility**: Fast language models can improve accessibility by:\n",
      "\t* Enabling text-to-speech and speech-to-text systems for people with disabilities.\n",
      "\t* Providing instant language translation for language barriers.\n",
      "9. **Research and Development**: Fast language models are essential for advancing research in natural language processing (NLP) and machine learning, enabling scientists to explore new ideas, test hypotheses, and develop more sophisticated models.\n",
      "10. **Future-Proofing**: As the amount of text data continues to grow exponentially, fast language models will become increasingly important for handling the sheer volume of information, ensuring that organizations can stay ahead of the curve and adapt to changing technologies and user behaviors.\n",
      "\n",
      "In summary, fast language models are crucial for efficient processing, improved user experience, scalability, real-time insights, competitive advantage, cost savings, enhanced security, accessibility, research and development, and future-proofing. Their importance will only continue to grow as the demand for NLP and language-based applications increases.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq()\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        # Set an optional system message. This sets the behavior of the\n",
    "        # assistant and can be used to provide specific instructions for\n",
    "        # how it should behave throughout the conversation.\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        # Set a user message for the assistant to respond to.\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "\n",
    "    # The language model which will generate the completion.\n",
    "    model=\"llama-3.3-70b-versatile\"\n",
    ")\n",
    "\n",
    "# Print the completion returned by the LLM.\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f0f456e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Transcription(text=' the capital of Mozambique', task='transcribe', language='English', duration=2.1, words=[{'word': 'the', 'start': 0, 'end': 0.12}, {'word': 'capital', 'start': 0.12, 'end': 0.5}, {'word': 'of', 'start': 0.5, 'end': 0.74}, {'word': 'Mozambique', 'start': 0.74, 'end': 1.4}], segments=[{'id': 0, 'seek': 0, 'start': 0, 'end': 2.1, 'text': ' the capital of Mozambique', 'tokens': [50365, 264, 4238, 295, 30208, 2173, 1925, 50470], 'temperature': 0, 'avg_logprob': -0.12320762, 'compression_ratio': 0.75757575, 'no_speech_prob': 4.8798006e-12}], x_groq={'id': 'req_01k3zvbxz2fv58205ysyt6d4dp'})\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from groq import Groq\n",
    "\n",
    "\n",
    "# Initialize the Groq client\n",
    "client = Groq()\n",
    "\n",
    "# Specify the path to the audio file\n",
    "filename =\"speech.wav\" # Replace with your audio file!\n",
    "\n",
    "# Open the audio file\n",
    "with open(filename, \"rb\") as file:\n",
    "    # Create a transcription of the audio file\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      file=file, # Required audio file\n",
    "      model=\"whisper-large-v3-turbo\", # Required model to use for transcription\n",
    "      prompt=\"Specify context or spelling\",  # Optional\n",
    "      response_format=\"verbose_json\",  # Optional\n",
    "      timestamp_granularities = [\"word\", \"segment\"], # Optional (must set response_format to \"json\" to use and can specify \"word\", \"segment\" (default), or both)\n",
    "      language=\"en\",  # Optional\n",
    "      temperature=0.0  # Optional\n",
    "    )\n",
    "    # To print only the transcription text, you'd use print(transcription.text) (here we're printing the entire transcription object to access timestamps)\n",
    "    print(json.dumps(transcription, indent=2, default=str))\n",
    "x= transcription.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9e21812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maputo\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"make your answers as brief as possible\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": x,\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "y=chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c3e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "speech_file_path = \"output.wav\" \n",
    "model = \"playai-tts\"\n",
    "voice = \"Fritz-PlayAI\"\n",
    "text = y\n",
    "response_format = \"wav\"\n",
    "\n",
    "response = client.audio.speech.create(\n",
    "    model=model,\n",
    "    voice=voice,\n",
    "    input=text,\n",
    "    response_format=response_format\n",
    ")\n",
    "\n",
    "response.write_to_file(speech_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
